{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Prompt Engineering\n",
    "\n",
    "Testing prompting strategies on the [MTOP Intent Dataset](https://huggingface.co/datasets/mteb/mtop_intent/viewer/de)\n",
    "> and evaluate the results against each other. The dataset contains instructions and labels indicating on which task the instruction was intended to prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key='lm-studio',  \n",
    "    base_url=\"http://localhost:1234/v1\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say only 'This is a test!' \",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.2-1b-instruct\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper code from the given file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt, system = None):\n",
    "    if system is None:\n",
    "        system = {'role': 'system',\n",
    "                  'content': 'You are a helpful AI assistant.'}\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        system | {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "        model=\"llama-3.2-1b-instruct\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def classify_one_example(example, prompt):\n",
    "    wrapper_prompt = \"\"\"\n",
    "    ### Task\n",
    "\n",
    "    You will be given instructions to a classification task and an input.\n",
    "    Do answer with only the label you assign based on the instructions provided. \n",
    "    The label should only be one word.\n",
    "\n",
    "    ### Instruction\n",
    "    {prompt}\n",
    "\n",
    "    ### Example\n",
    "    {example}\n",
    "\n",
    "    ### Label\n",
    "    \"\"\"\n",
    "    return get_answer(wrapper_prompt.format(prompt = prompt, example = example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_one_example(\n",
    "    example = 'Today we can go to the playground, since it is sunny outside',\n",
    "    prompt = ('Classify the sentiment of the given example.' + \n",
    "              'Only use 1 for positive, 0 for neutral or -1 for negative as classes.')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'label', 'label_text'],\n",
       "    num_rows: 15667\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data from hugging face dataset\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ds = load_dataset(\"mteb/mtop_intent\", \"en\")\n",
    "\n",
    "train_data = ds['train']\n",
    "val_data = ds['validation']\n",
    "test_data = ds['test']\n",
    "\n",
    "#converting in Pandas Dataframe\n",
    "train_df = train_data.to_pandas()\n",
    "\n",
    "#checking null values\n",
    "train_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  25,  24,   0,  59,  33,  42,  18,  14,  48,  43,  60,  63,\n",
       "        29,  16,  34,   3,  32,  41,  15,  51,  98,  52,  22,  47,   4,\n",
       "        11,  49,  38,  71,  57,  86,  53,  55,  44,   7,  36,  97,  50,\n",
       "        61,  77,   5,  30,  21,  65,  35,  45,  67,  54,  20,  26,  80,\n",
       "        89,  27,  37,  46,  72,  12,  10,  75,  19,  62,  17,  88, 101,\n",
       "        69,  31,   6,  68,  56,   9,  40,  92,  85,  66,  74,  13, 110,\n",
       "         2,  79,  70,  90,  28,  81,  64,  58,   8, 100,  39,  96,  84,\n",
       "        94, 104, 103, 106,  93,  76,  78, 105,  82,  73, 108, 107,  95,\n",
       "        91, 102,  23, 112, 109,  83,  99,  87, 111])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking different labels \n",
    "train_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3232343436343136</td>\n",
       "      <td>Has Angelika Kratzer video messaged me?</td>\n",
       "      <td>1</td>\n",
       "      <td>GET_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3232353833343937</td>\n",
       "      <td>text Matthew and Helen that are you free</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3232353832303532</td>\n",
       "      <td>show me video messages from Atlas</td>\n",
       "      <td>1</td>\n",
       "      <td>GET_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3232313731303530</td>\n",
       "      <td>i want you to start recording a video message ...</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3232353833373337</td>\n",
       "      <td>I need you to message Zachary Fletcher</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15599</th>\n",
       "      <td>3231323833303439</td>\n",
       "      <td>Message the list if anyone is going tonight</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>3231373233393830</td>\n",
       "      <td>could I video message Brynlee</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>3231323831383134</td>\n",
       "      <td>Ask my mom what time I should come over</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>3232353735313533</td>\n",
       "      <td>send Izzy that Facebook video message</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15665</th>\n",
       "      <td>3232353833313232</td>\n",
       "      <td>i would like to message my parents text</td>\n",
       "      <td>0</td>\n",
       "      <td>SEND_MESSAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1141 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0      3232343436343136            Has Angelika Kratzer video messaged me?   \n",
       "3      3232353833343937           text Matthew and Helen that are you free   \n",
       "15     3232353832303532                  show me video messages from Atlas   \n",
       "30     3232313731303530  i want you to start recording a video message ...   \n",
       "71     3232353833373337             I need you to message Zachary Fletcher   \n",
       "...                 ...                                                ...   \n",
       "15599  3231323833303439        Message the list if anyone is going tonight   \n",
       "15602  3231373233393830                      could I video message Brynlee   \n",
       "15625  3231323831383134            Ask my mom what time I should come over   \n",
       "15664  3232353735313533              send Izzy that Facebook video message   \n",
       "15665  3232353833313232            i would like to message my parents text   \n",
       "\n",
       "       label    label_text  \n",
       "0          1   GET_MESSAGE  \n",
       "3          0  SEND_MESSAGE  \n",
       "15         1   GET_MESSAGE  \n",
       "30         0  SEND_MESSAGE  \n",
       "71         0  SEND_MESSAGE  \n",
       "...      ...           ...  \n",
       "15599      0  SEND_MESSAGE  \n",
       "15602      0  SEND_MESSAGE  \n",
       "15625      0  SEND_MESSAGE  \n",
       "15664      0  SEND_MESSAGE  \n",
       "15665      0  SEND_MESSAGE  \n",
       "\n",
       "[1141 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For label = 1 it is a Get Message category (label text value)\n",
    "train_df_original = train_df.copy()\n",
    "train_df = train_df[(train_df['label'] == 1) | (train_df['label'] == 0)].set_index('id')\n",
    "\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Working with 5 sentences and classifying them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching only two rows\n",
    "\n",
    "df = train_df[['text', 'label']]\n",
    "\n",
    "# Convert DataFrame to a dictionary\n",
    "data_dict = df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on 20 examples and testing different prompt strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "prompt_accuracy_list = []\n",
    "\n",
    "def prompt_strategy(prompt, data, strategy_title):\n",
    "     \n",
    "    results = []\n",
    "\n",
    "    for record in data[0:20]:\n",
    "        text = record['text']\n",
    "        true_label = record['label']\n",
    "        predicted_label = classify_one_example(text,prompt)\n",
    "        if predicted_label == 'GET_MESSAGE': \n",
    "            predicted_label = 1\n",
    "        elif predicted_label == \"OTHER\": \n",
    "            predicted_label = 0\n",
    "\n",
    "        # print(\"predicted_label.........\", predicted_label)\n",
    "        \n",
    "        if predicted_label == 1 or predicted_label == 0: \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"true_label\": true_label,\n",
    "                \"predicted_label\": predicted_label,\n",
    "                \"prompt_type\": 'Prompt 1'\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(results_df['true_label'], results_df['predicted_label'])\n",
    "    \n",
    "    \n",
    "    prompt_accuracy_list.append(pd.DataFrame({\n",
    "    'Strategy': [strategy_title],\n",
    "    'Accuracy Score': [accuracy]}))\n",
    "    \n",
    "    final_df = pd.concat(prompt_accuracy_list, ignore_index=True)\n",
    "   \n",
    "   \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strategy  Accuracy Score\n",
       "0  Prompt 1        0.263158"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Classify on the task instructed by the given example.\n",
    "Only use 'GET_MESSAGE' or 'OTHER' as class-labels. \n",
    "\"\"\"\n",
    "\n",
    "# Processing\n",
    "prompt_strategy(prompt= prompt_1, data= data_dict, strategy_title=\"Prompt 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strategy  Accuracy Score\n",
       "0  Prompt 1        0.263158\n",
       "1  Prompt 2        0.421053"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_2 = prompt_1 + \"\"\"\n",
    "Think and analyse about which task the instruction prompts before you give the label. \n",
    "Take note of verbs in the instruction hinting at the result the user \n",
    "is expecting.\n",
    "\"\"\"\n",
    "\n",
    "prompt_strategy(prompt= prompt_2, data= data_dict, strategy_title=\"Prompt 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strategy  Accuracy Score\n",
       "0  Prompt 1        0.263158\n",
       "1  Prompt 2        0.421053\n",
       "2  Prompt 3        0.222222"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt_3 = prompt_2 + \"\"\"\n",
    "Examples should be labeled 'GET_MESSAGE' if the request could be answered by\n",
    "looking up a message.\n",
    "In every other case, the label should be 'OTHER'.\n",
    "\"\"\"\n",
    "\n",
    "prompt_strategy(prompt= prompt_3, data= data_dict, strategy_title=\"Prompt 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strategy  Accuracy Score\n",
       "0  Prompt 1        0.263158\n",
       "1  Prompt 2        0.421053\n",
       "2  Prompt 3        0.222222\n",
       "3  Prompt 4        0.250000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_4 = prompt_2 + \"\"\" These are some examples for class labelling: \n",
    "Message the list if anyone is going tonight - OTHER\n",
    "show me video messages from Atlas - GET_MESSAGE\n",
    "\"\"\"\n",
    "\n",
    "prompt_strategy(prompt= prompt_4, data= data_dict, strategy_title=\"Prompt 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt 5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strategy  Accuracy Score\n",
       "0  Prompt 1        0.263158\n",
       "1  Prompt 2        0.421053\n",
       "2  Prompt 3        0.222222\n",
       "3  Prompt 4        0.250000\n",
       "4  Prompt 5        0.600000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_5 = prompt_4 + \"\"\"Do label the message as a GET_MESSAGE when there is certain kind of a request. For example: \n",
    "i want to see texts from cousin Maria- GET_MESSAGE\n",
    "Did my family text me - GET_MESSAGE\n",
    "lets see my texts from my wife Brycen - GET_MESSAGE\n",
    "\"\"\"\n",
    "\n",
    "prompt_strategy(prompt= prompt_5, data= data_dict, strategy_title=\"Prompt 5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing First 20 Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has Angelika Kratzer video messaged me?\n",
      "text Matthew and Helen that are you free\n",
      "show me video messages from Atlas\n",
      "i want you to start recording a video message for Amelia\n",
      "I need you to message Zachary Fletcher\n",
      "let's start recording a video message for Sean\n",
      "Please record a video message for kid\n",
      "message Angela and tell her that the movie marathon is at Gloria's house in Overland Park\n",
      "Id like you to send a video\n",
      "Start recording for a video message to Macie Larita\n",
      "Message Reggie to ask him what time he will arrive.\n",
      "MESSAGE DENNIE AND LET HER KNOW I WOULD LIKE TO MEET FOR LUNCH TOMORROW.\n",
      "please send my family text\n",
      "Send a happy birthday message to dad.\n",
      "Send a message to Kevin asking if he has heard from my husband.\n",
      "Message Morgan's friends that we will have a surprise party for her on September 5th at 8pm\n",
      "record a video message for Chana Stamps\n",
      "respond to Kamryn with a video\n",
      "Has Lila Kiritsy sent me any messages?\n",
      "text Katey and Helen that are you free\n"
     ]
    }
   ],
   "source": [
    "for data in data_dict[0:20]: \n",
    "    print(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Processing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: This is an example text, full of unnecessary punctuation!!! And extra spaces... :)\n",
      "Processed Text: example text full unnecessary punctuation extra space\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download resources for nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text, remove_stopwords=True, lemmatize=True):\n",
    " \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Tokenize the text (split into words)\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Rejoin words into a single string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example Usage\n",
    "raw_text = \"This is an example text, full of unnecessary punctuation!!! And extra spaces... :)\"\n",
    "processed_text = preprocess_text(raw_text)\n",
    "print(\"Original Text:\", raw_text)\n",
    "print(\"Processed Text:\", processed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def prompt_strategy_preprocessed_text(prompt, data, strategy_title):\n",
    "     \n",
    "    results = []\n",
    "\n",
    "    for record in data[0:20]:\n",
    "        #pre processing the text \n",
    "        text = preprocess_text(record['text'])\n",
    "        true_label = record['label']\n",
    "        predicted_label = classify_one_example(text,prompt)\n",
    "        if predicted_label == 'GET_MESSAGE': \n",
    "            predicted_label = 1\n",
    "        elif predicted_label == \"OTHER\": \n",
    "            predicted_label = 0\n",
    "\n",
    "        \n",
    "        if predicted_label == 1 or predicted_label == 0: \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"true_label\": true_label,\n",
    "                \"predicted_label\": predicted_label,\n",
    "                \"prompt_type\": 'Prompt 1'\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(results_df['true_label'], results_df['predicted_label'])\n",
    "    \n",
    "    \n",
    "    prompt_accuracy_list.append(pd.DataFrame({\n",
    "    'Strategy': [strategy_title],\n",
    "    'Accuracy Score': [accuracy]}))\n",
    "    \n",
    "    final_df = pd.concat(prompt_accuracy_list, ignore_index=True)\n",
    "   \n",
    "   \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt 5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prompt 1 Pre-Processed Text</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Strategy  Accuracy Score\n",
       "0                     Prompt 1        0.263158\n",
       "1                     Prompt 2        0.421053\n",
       "2                     Prompt 3        0.222222\n",
       "3                     Prompt 4        0.250000\n",
       "4                     Prompt 5        0.600000\n",
       "5  Prompt 1 Pre-Processed Text        0.500000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_strategy_preprocessed_text(prompt= prompt_1, data= data_dict, strategy_title=\"Prompt 1 Pre-Processed Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt 5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prompt 1 Pre-Processed Text</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prompt 2 Pre-Processed Text</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Strategy  Accuracy Score\n",
       "0                     Prompt 1        0.263158\n",
       "1                     Prompt 2        0.421053\n",
       "2                     Prompt 3        0.222222\n",
       "3                     Prompt 4        0.250000\n",
       "4                     Prompt 5        0.600000\n",
       "5  Prompt 1 Pre-Processed Text        0.500000\n",
       "6  Prompt 2 Pre-Processed Text        0.250000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_strategy_preprocessed_text(prompt= prompt_2, data= data_dict, strategy_title=\"Prompt 2 Pre-Processed Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt 5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prompt 1 Pre-Processed Text</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prompt 2 Pre-Processed Text</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prompt 5 Pre-Processed Text</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Strategy  Accuracy Score\n",
       "0                     Prompt 1        0.263158\n",
       "1                     Prompt 2        0.421053\n",
       "2                     Prompt 3        0.222222\n",
       "3                     Prompt 4        0.250000\n",
       "4                     Prompt 5        0.600000\n",
       "5  Prompt 1 Pre-Processed Text        0.500000\n",
       "6  Prompt 2 Pre-Processed Text        0.250000\n",
       "7  Prompt 5 Pre-Processed Text        0.450000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_strategy_preprocessed_text(prompt= prompt_5, data= data_dict, strategy_title=\"Prompt 5 Pre-Processed Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obervation: \n",
    "\n",
    "The accuracy is not increasing in every case on Text Pre-Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
